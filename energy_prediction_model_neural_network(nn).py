# -*- coding: utf-8 -*-
"""Energy_Prediction_Model_Neural_Network(NN).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15exgn1_hImcbiqI5cdMEuIrY2Yup68dl
"""

#hyper tuninig of parameters in neural network
!pip install -q -U keras-tuner
from tensorflow import keras
import keras_tuner

pip install scikeras

import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from keras_tuner import RandomSearch
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.wrappers.scikit_learn import KerasRegressor
import scikeras
from scikeras.wrappers import KerasRegressor
import warnings
warnings.filterwarnings('ignore')

df = pd.concat(map(pd.read_csv,["/content/gt_2011.csv",
                                  "/content/gt_2012.csv",
                                  "/content/gt_2013.csv",
                                  "/content/gt_2014.csv",
                                  "/content/gt_2015.csv"]),ignore_index=True)
df.shape

df.head(2)

X = df[['AT','AP','AH','AFDP','GTEP','TIT','TAT','CDP','CO','NOX']]
Y = df['TEY']

X.shape,Y.shape

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.3, random_state=7)
X_train.shape,X_test.shape,Y_train.shape,Y_test.shape

"""- Standardize features by removing the mean and scaling to unit variance"""

scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = Sequential()
model.add(Dense(128, input_dim=10, activation='relu'))
model.add(Dense(64, activation='relu'))
#Output layer
model.add(Dense(1, activation='linear'))

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])
model.summary()

history = model.fit(X_train_scaled, Y_train, validation_split=0.2, epochs =100)

Y_pred = model.predict(X_test_scaled)
mse_nn = mean_squared_error(Y_test, Y_pred)
mae_nn = mean_absolute_error(Y_test,Y_pred)
r2_nn= r2_score(Y_test,Y_pred)

mse_neural, mae_neural = model.evaluate(X_test_scaled, Y_test)
print('Mean squared error from neural net: ', mse_nn)
print('Mean absolute error from neural net: ', mae_nn)
print('R2 from neural net: ', r2_nn)

from matplotlib import pyplot as plt
#plot the training and validation accuracy and loss at each epoch
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['mae']
val_acc = history.history['val_mae']
plt.plot(epochs, acc, 'y', label='Training MAE')
plt.plot(epochs, val_acc, 'r', label='Validation MAE')
plt.title('Training and validation MAE')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def fun_regression_ann( optimizer='adam', loss='mse',learning_rate=0.001):
    model = Sequential()
    model.add(Dense(28, input_dim=10,activation='relu'))
    model.add(Dense(14, activation='relu'))
    model.add(Dense(1,activation='linear' ))
    model.compile(loss=loss, optimizer=optimizer)
    return model

fun_regression_ann().summary()

param_grid = {'optimizer': ['adam'],
     'loss': ['mse','mae'],
     'epochs': [20, 100, 200, 500]}

grid_search = GridSearchCV(
    estimator=KerasRegressor(fun_regression_ann,learning_rate=0.001,verbose=1),
    param_grid=param_grid,cv=3)

grid_result = grid_search.fit(X_train_scaled, Y_train)

grid_search.best_params_

accuracy = grid_search.best_score_
accuracy

estimator = KerasRegressor(build_fn=fun_regression_ann, verbose=True,loss='mse',optimizer='adam',epochs=500,learning_rate=0.001)
estimator.fit(X_train_scaled, Y_train)

prediction = estimator.predict(X_test_scaled)
mse_krr = mean_squared_error(Y_test, prediction)
mae_krr=mean_absolute_error(Y_test,prediction)
r2_krr= r2_score(Y_test,prediction)
print('Mean squared error (MSE): ', mse_krr)
print('Mean absolute error (MAE): ', mae_krr)
print('R2 Score: ',r2_krr)